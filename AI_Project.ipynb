{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Airtifical Intelligence Project\n",
        "Assignment4 (MIX),  Title:  Classify building usage type from street acquired images using genetic algorithm and compare with other optimizers (Adam, GD, SGD)**\n",
        "Ayush Pandey, 20071 "
      ],
      "metadata": {
        "id": "e6_e-hVYmZ1b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLdZblspO9lj",
        "outputId": "0bc27d53-5343-4f6c-d4e5-1ba4a23e1250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#Mount Google colab to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41qFWJ3ieumd"
      },
      "outputs": [],
      "source": [
        "#import important library\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwPOpeaMQRqu"
      },
      "outputs": [],
      "source": [
        "#unzip test images\n",
        "!unzip -q \"/content/gdrive/My Drive/AI Project/test-20230329T110207Z-001.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wlsm8n_Qdtc"
      },
      "outputs": [],
      "source": [
        "#unzip train images\n",
        "!unzip -q \"/content/gdrive/My Drive/AI Project/train-20230329T110010Z-001.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g4c7iM5JJJ2",
        "outputId": "7f3ba01a-ae9e-40d8-c52c-8fb353a47634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from efficientnet_pytorch) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->efficientnet_pytorch) (3.10.7)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->efficientnet_pytorch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->efficientnet_pytorch) (3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->efficientnet_pytorch) (4.5.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->efficientnet_pytorch) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->efficientnet_pytorch) (3.1.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->efficientnet_pytorch) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->efficientnet_pytorch) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16444 sha256=45fb1b000204d67c8c5ecbc1f2da9746150293bf0592ab11e55a4a1172df88d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/16/24/752e89d88d333af39a288421e64d613b5f652918e39ef1f8e3\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Twy6nbpIQvci"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir):\n",
        "        self.root_dir = root_dir\n",
        "        self.samples = []\n",
        "        for subdir in os.listdir(root_dir):\n",
        "            if subdir in [\"commercial\", \"industrial\", \"residential\", \"others\"]:\n",
        "                subpath = os.path.join(root_dir, subdir)\n",
        "                for filename in os.listdir(subpath):\n",
        "                    filepath = os.path.join(subpath, filename)\n",
        "                    self.samples.append((filepath, subdir))\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        img = Image.open(img_path)\n",
        "        img = self.transform(img)\n",
        "        label_map = {\n",
        "            \"commercial\": 0,\n",
        "            \"industrial\": 1,\n",
        "            \"residential\": 2,\n",
        "            \"others\": 3,\n",
        "        }\n",
        "        return img, label_map[label]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Zse9W67TAyn"
      },
      "outputs": [],
      "source": [
        "dataset = CustomDataset(root_dir=\"/content/train\")\n",
        "dataloader = DataLoader(dataset, batch_size=100, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test = CustomDataset(root_dir=\"/content/test\")\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "ATBHYhQfxhyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-08EO7efc9q"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model.classifier[6].weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fhV_f1JauKx",
        "outputId": "2bc1e8a9-2130-45ee-c929-8479a32d540b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vgg_model.features[2].weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngmu7MfxaGV6",
        "outputId": "618a6fca-a0a2-4f7a-9105-0f3171015d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[-3.0606e-02, -9.8520e-02, -1.3260e-01],\n",
            "          [ 6.8208e-03, -8.3483e-02, -1.6697e-01],\n",
            "          [ 3.1015e-02, -6.5803e-02, -1.3171e-01]],\n",
            "\n",
            "         [[ 4.7407e-02, -2.7588e-02, -5.1127e-02],\n",
            "          [ 7.0129e-02,  8.2528e-03, -1.8340e-02],\n",
            "          [ 6.9918e-02,  3.8993e-02,  1.6228e-02]],\n",
            "\n",
            "         [[ 7.0700e-02,  5.2703e-03, -4.7362e-02],\n",
            "          [ 8.4006e-02,  4.9190e-02, -1.6474e-03],\n",
            "          [ 8.5166e-03,  2.2350e-02,  5.9118e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7666e-02,  2.1778e-02, -9.4606e-03],\n",
            "          [ 2.5511e-02,  4.1186e-03, -3.4521e-02],\n",
            "          [ 2.0150e-02,  3.7068e-02, -1.3509e-02]],\n",
            "\n",
            "         [[ 2.1684e-02,  4.1812e-02,  5.8284e-02],\n",
            "          [ 2.7431e-02,  3.6847e-02,  3.4335e-02],\n",
            "          [-9.4839e-03,  1.9745e-02,  5.0264e-02]],\n",
            "\n",
            "         [[ 2.1769e-02, -2.1388e-02, -9.9363e-02],\n",
            "          [-5.7156e-02, -7.1328e-02, -7.7600e-02],\n",
            "          [-3.7508e-02, -2.5453e-02, -4.5096e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.3319e-02, -7.7979e-02, -1.3496e-01],\n",
            "          [-3.7411e-02, -8.1807e-02, -1.4195e-01],\n",
            "          [-4.1913e-02, -1.0756e-01, -1.6164e-01]],\n",
            "\n",
            "         [[-6.8725e-03,  4.8598e-02,  1.5008e-02],\n",
            "          [ 1.8636e-02,  9.8393e-03, -1.5973e-02],\n",
            "          [ 9.5164e-04, -3.2665e-02, -3.5824e-02]],\n",
            "\n",
            "         [[ 1.4780e-02, -1.4260e-02, -4.4468e-02],\n",
            "          [-1.8438e-02,  1.4841e-02, -8.2337e-02],\n",
            "          [ 1.8329e-02,  2.1435e-03,  9.0911e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.0342e-02,  3.6146e-02,  2.5515e-02],\n",
            "          [ 1.5779e-02,  3.1012e-03, -1.0942e-02],\n",
            "          [ 2.3790e-02,  1.6440e-02, -2.5835e-02]],\n",
            "\n",
            "         [[-2.2844e-02,  2.5371e-03, -2.1714e-02],\n",
            "          [ 3.9534e-04, -6.4903e-03,  1.6979e-02],\n",
            "          [-4.7200e-03, -2.2301e-02, -2.1298e-02]],\n",
            "\n",
            "         [[-2.8434e-02, -2.6771e-02,  2.7432e-02],\n",
            "          [-5.8088e-02, -5.5869e-02,  7.0289e-02],\n",
            "          [-6.4470e-02, -3.8172e-02,  4.1569e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2508e-02,  2.4738e-02,  5.3893e-02],\n",
            "          [-2.5838e-02, -1.6176e-02,  2.8344e-02],\n",
            "          [ 1.2948e-02,  9.0717e-03,  2.8181e-02]],\n",
            "\n",
            "         [[-7.9309e-02, -8.8828e-02, -5.5737e-02],\n",
            "          [-4.8359e-02, -1.1139e-01, -1.0901e-02],\n",
            "          [ 3.4640e-02,  2.3298e-02,  1.1002e-01]],\n",
            "\n",
            "         [[-4.3616e-02, -1.6598e-02, -1.0547e-02],\n",
            "          [ 2.8982e-02,  4.5279e-02,  1.6869e-02],\n",
            "          [ 8.8168e-02,  1.2599e-01,  7.2292e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3967e-03,  1.5333e-02, -1.7196e-02],\n",
            "          [-8.3107e-03, -1.2905e-02, -1.4394e-03],\n",
            "          [ 6.3471e-03,  1.7825e-03, -3.3770e-02]],\n",
            "\n",
            "         [[-7.9354e-03, -5.8610e-03, -7.6292e-05],\n",
            "          [ 6.8661e-04, -6.0019e-03,  1.0119e-02],\n",
            "          [ 3.0581e-02,  1.6821e-02,  3.2570e-02]],\n",
            "\n",
            "         [[ 5.9351e-02, -7.4398e-03,  3.8274e-02],\n",
            "          [-2.0792e-02, -4.8833e-02,  4.0274e-02],\n",
            "          [ 2.3138e-02,  7.4794e-03,  3.5027e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.5464e-02, -2.9275e-02,  1.0282e-02],\n",
            "          [-4.6952e-02, -4.9473e-02,  1.7632e-02],\n",
            "          [-4.3815e-02, -2.4871e-02, -2.4908e-02]],\n",
            "\n",
            "         [[-1.9359e-02,  1.5948e-02, -6.3554e-02],\n",
            "          [ 3.0096e-02,  2.8515e-02, -6.4439e-02],\n",
            "          [-1.4547e-02,  2.2238e-03, -6.3371e-02]],\n",
            "\n",
            "         [[-2.7915e-02, -2.1738e-02, -5.1691e-02],\n",
            "          [ 1.0889e-02, -5.1994e-02, -5.4649e-02],\n",
            "          [-3.9741e-02,  5.2832e-04,  3.5375e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.9130e-03,  1.0995e-03, -7.4082e-03],\n",
            "          [ 1.8428e-03,  8.2602e-03,  1.8680e-02],\n",
            "          [ 1.1709e-02,  6.9263e-03,  3.3630e-02]],\n",
            "\n",
            "         [[ 8.9195e-03,  3.2807e-02,  3.9282e-02],\n",
            "          [-2.5044e-03,  1.7645e-03,  1.4056e-02],\n",
            "          [-5.4708e-03,  9.5572e-03,  2.8639e-02]],\n",
            "\n",
            "         [[-3.0241e-02, -6.7225e-02, -7.4299e-02],\n",
            "          [-3.6222e-02, -9.7721e-03,  6.1669e-02],\n",
            "          [-1.6392e-02,  5.8156e-02,  1.2894e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 4.0321e-02,  3.7677e-02,  1.7181e-02],\n",
            "          [ 4.0298e-02,  2.9479e-02,  1.6698e-02],\n",
            "          [-4.8739e-03,  2.1128e-02, -2.6295e-03]],\n",
            "\n",
            "         [[ 3.1079e-02, -1.6475e-02,  1.0769e-02],\n",
            "          [-5.8626e-02, -4.6721e-02, -2.7764e-02],\n",
            "          [-3.1245e-02,  1.7635e-02, -1.2211e-02]],\n",
            "\n",
            "         [[-9.8675e-02, -9.8915e-02, -1.3225e-01],\n",
            "          [ 7.3214e-02, -7.5238e-03, -7.4033e-02],\n",
            "          [ 1.7070e-01,  1.8346e-01,  3.3906e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.5318e-02,  3.2680e-02,  5.2874e-03],\n",
            "          [-4.1894e-03,  2.0011e-02,  1.6021e-02],\n",
            "          [-4.8276e-03, -2.9130e-02,  7.4975e-04]],\n",
            "\n",
            "         [[ 7.1959e-03, -5.1528e-03,  5.1333e-03],\n",
            "          [-8.6466e-04,  1.2417e-02,  2.0805e-02],\n",
            "          [ 2.4862e-03, -1.3194e-02,  3.6563e-03]],\n",
            "\n",
            "         [[ 3.2415e-02,  1.0823e-02,  3.1720e-02],\n",
            "          [-8.4911e-03,  5.9831e-02,  3.4606e-02],\n",
            "          [-2.0674e-02,  1.6525e-02, -1.3183e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.6955e-02,  1.0821e-02,  7.9260e-02],\n",
            "          [ 1.0361e-02, -3.3380e-02,  5.2775e-02],\n",
            "          [-3.8372e-02, -3.0964e-02,  6.5422e-02]],\n",
            "\n",
            "         [[ 5.4925e-02, -1.9160e-01,  9.9709e-02],\n",
            "          [-1.8754e-01,  1.3248e-02,  2.4748e-01],\n",
            "          [-5.6662e-03,  2.8737e-02, -8.9787e-02]],\n",
            "\n",
            "         [[-1.4905e-01, -1.2974e-01,  1.7649e-01],\n",
            "          [-1.5774e-01,  1.5130e-01,  8.4126e-02],\n",
            "          [ 9.4988e-02,  8.5186e-02, -3.3635e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2278e-02,  3.3348e-02, -1.0524e-02],\n",
            "          [ 5.0310e-02, -9.1280e-03, -3.3890e-02],\n",
            "          [ 1.3459e-02, -2.9601e-02,  2.6862e-02]],\n",
            "\n",
            "         [[ 3.1006e-02,  2.8481e-02,  5.2361e-03],\n",
            "          [ 3.8914e-03, -1.8899e-02, -2.1819e-02],\n",
            "          [-8.4505e-03, -3.6632e-02, -1.9476e-02]],\n",
            "\n",
            "         [[ 2.3835e-02,  4.5658e-02,  6.7297e-02],\n",
            "          [ 1.1103e-02,  3.2035e-02, -5.8449e-02],\n",
            "          [ 2.6805e-02, -9.3975e-02, -4.0504e-02]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_params = []\n",
        "for i in vgg_model.parameters():\n",
        "  list_of_params.append(i)\n",
        "\n",
        "optimizable_params = [list_of_params[-1].shape, list_of_params[-2].shape]"
      ],
      "metadata": {
        "id": "McZcfLs4Txe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in vgg_model.parameters():\n",
        "  if param.shape not in optimizable_params:\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "wkaJWfGGUuN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_optimize = []\n",
        "\n",
        "for param in vgg_model.parameters():\n",
        "  if param.shape in optimizable_params:\n",
        "    param.requires_grad = True\n",
        "    to_optimize.append(param)"
      ],
      "metadata": {
        "id": "C5ZFJ28SVs6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_optimize[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXYf7gZGV70o",
        "outputId": "577775a0-0ee0-41c3-ae1b-ca24711dea1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.0041,  0.0009, -0.0053,  0.0151], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genetic_variable = to_optimize[0].detach().cpu().numpy().flatten().shape"
      ],
      "metadata": {
        "id": "FSG-NGp9WCEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_array_1 = np.random.rand(16384)\n",
        "\n",
        "# Threshold the array to obtain a binary numpy array of 1s and 0s\n",
        "binary_array_1 = (random_array_1 >= 0.5).astype(int)"
      ],
      "metadata": {
        "id": "DepoEUJXWbKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_array = torch.tensor(binary_array_1.reshape(4, 4096), requires_grad = False)"
      ],
      "metadata": {
        "id": "Xg70Zo3sWvgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in vgg_model.parameters():\n",
        "  if param.shape in optimizable_params[0]:\n",
        "    param = best_a"
      ],
      "metadata": {
        "id": "KlqMhzcQWvZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in vgg_model.parameters():\n",
        "  if param.shape in optimizable_params[0]:\n",
        "    print(param)"
      ],
      "metadata": {
        "id": "HO3_GWr0XYXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the VGG model\n",
        "vgg_model = models.vgg16(pretrained=True)\n",
        "\n",
        "# Freeze all the layers of the VGG model\n",
        "for param in vgg_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "\n",
        "# Replace the last layer of the VGG model with a new fully connected layer with 4 neurons\n",
        "num_features = vgg_model.classifier[-1].in_features\n",
        "vgg_model.classifier[-1] = nn.Linear(num_features, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHQePKo8sHEv",
        "outputId": "3e8d11e5-1c15-42bf-8a9c-f8efc9e863f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "lBzZmMFBBEDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vgg model\n",
        "print(vgg_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrXarM3TBSPQ",
        "outputId": "87ab827a-7a46-4099-b495-8ee063fc8285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting vgg to out input data for a batch\n",
        "for img, label in dataloader:\n",
        "    output = vgg_model(img)\n",
        "    truth = label\n",
        "    break"
      ],
      "metadata": {
        "id": "gDHTfnuXRvC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = torch.argmax(output, dim = 1).detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "-Wx_aL53SOIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "truth = truth.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "4mqc9FChSi_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(truth, prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67ELsHSXSs6C",
        "outputId": "e0145de0-76d5-4774-af37-20c232896e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        12\n",
            "           1       0.00      0.00      0.00         3\n",
            "           2       0.00      0.00      0.00         8\n",
            "           3       0.28      1.00      0.44         9\n",
            "\n",
            "    accuracy                           0.28        32\n",
            "   macro avg       0.07      0.25      0.11        32\n",
            "weighted avg       0.08      0.28      0.12        32\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting label for whole image set from vgg model\n",
        "output=[]\n",
        "truth=[]\n",
        "for img, label in dataloader:\n",
        "    output.append(vgg_model(img))\n",
        "    truth.append(label)\n",
        "    "
      ],
      "metadata": {
        "id": "Avxs4KH9bZGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arrays[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAlaFErPp4EM",
        "outputId": "cd7dd578-1738-452f-f561-c99bff1b8af0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16384,)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Generate 6 arrays of 1s and 0s of size 16384\n",
        "arrays = [np.random.randint(2, size=16384) for i in range(6)]\n",
        "\n",
        "# Reshape the arrays to (4, 4096) and convert to torch tensors\n",
        "binary_tensors = [torch.from_numpy(arr.reshape((4, 4096))) for arr in arrays]"
      ],
      "metadata": {
        "id": "gqpFR9qvqhgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For binary tensor 1\n",
        "vgg_model.classifier[6].weight.data = nn.Parameter((binary_tensors[0]).float())"
      ],
      "metadata": {
        "id": "T_CD1TRL1jQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img, label in dataloader:\n",
        "    output1=vgg_model(img)\n",
        "    truth1=label\n",
        "    break\n",
        "    "
      ],
      "metadata": {
        "id": "DQ2NOIxC1nOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction1 = torch.argmax(output1, dim = 1).detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "cDp8OJPz3hxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "truth1 = truth1.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "2mDG87r03vFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(truth1, prediction1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sbuvfvq630mr",
        "outputId": "30c95c6b-52d6-45cc-c2e6-5f2ee0043dbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         9\n",
            "           1       0.05      1.00      0.10         1\n",
            "           2       0.40      0.25      0.31        16\n",
            "           3       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.16        32\n",
            "   macro avg       0.11      0.31      0.10        32\n",
            "weighted avg       0.20      0.16      0.16        32\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For binary tensor 2\n",
        "vgg_model.classifier[6].weight.data = nn.Parameter((binary_tensors[1]).float())"
      ],
      "metadata": {
        "id": "xFOrsMb136qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img, label in dataloader:\n",
        "    output2=vgg_model(img)\n",
        "    truth2=label\n",
        "    break\n",
        "    "
      ],
      "metadata": {
        "id": "_8c_FDck459r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction2 = torch.argmax(output2, dim = 1).detach().cpu().numpy()\n",
        "truth2 = truth2.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "IQLVBb8o5KDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(truth2, prediction2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrHS57Pv5fux",
        "outputId": "76d12789-34aa-4f10-fa46-7bd88fb801ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.18      0.30      0.23        20\n",
            "           1       0.09      0.20      0.12        10\n",
            "           2       0.62      0.18      0.28        56\n",
            "           3       0.07      0.14      0.10        14\n",
            "\n",
            "    accuracy                           0.20       100\n",
            "   macro avg       0.24      0.21      0.18       100\n",
            "weighted avg       0.41      0.20      0.23       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For binary tensor 3\n",
        "vgg_model.classifier[6].weight.data = nn.Parameter((binary_tensors[2]).float())"
      ],
      "metadata": {
        "id": "ChEgtsyY5jB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img, label in dataloader:\n",
        "    output3=vgg_model(img)\n",
        "    truth3=label\n",
        "    break"
      ],
      "metadata": {
        "id": "Sn9J31kS5u17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction3 = torch.argmax(output3, dim = 1).detach().cpu().numpy()\n",
        "truth3 = truth3.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "RUzdPWli5xR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(truth3, prediction3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ACqK7Sh6FJq",
        "outputId": "69544667-96ec-49e8-bba2-3ebe57d96287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.32      0.32        28\n",
            "           1       0.00      0.00      0.00        11\n",
            "           2       0.37      0.38      0.37        45\n",
            "           3       0.05      0.06      0.05        16\n",
            "\n",
            "    accuracy                           0.27       100\n",
            "   macro avg       0.18      0.19      0.19       100\n",
            "weighted avg       0.26      0.27      0.27       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For binary tensor 4\n",
        "vgg_model.classifier[6].weight.data = nn.Parameter((binary_tensors[3]).float())"
      ],
      "metadata": {
        "id": "ArfGpaKH6H6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img, label in dataloader:\n",
        "    output4=vgg_model(img)\n",
        "    truth4=label\n",
        "    break"
      ],
      "metadata": {
        "id": "gib8Y7196OAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction4 = torch.argmax(output4, dim = 1).detach().cpu().numpy()\n",
        "truth4 = truth4.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "D5iswN2Y6Qhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(truth4, prediction4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6-aX3UN6lmp",
        "outputId": "26e3c4d3-e4fc-413f-d69a-4a7d6e9bcd16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.20      0.26        20\n",
            "           1       0.11      0.30      0.16        10\n",
            "           2       0.60      0.47      0.53        53\n",
            "           3       0.30      0.35      0.32        17\n",
            "\n",
            "    accuracy                           0.38       100\n",
            "   macro avg       0.34      0.33      0.32       100\n",
            "weighted avg       0.45      0.38      0.40       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For binary tensor 5\n",
        "vgg_model.classifier[6].weight.data = nn.Parameter((binary_tensors[4]).float())"
      ],
      "metadata": {
        "id": "IaN636ev6pij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img, label in dataloader:\n",
        "    output5=vgg_model(img)\n",
        "    truth5=label\n",
        "    break"
      ],
      "metadata": {
        "id": "HNTNTU3C6t-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction5 = torch.argmax(output5, dim = 1).detach().cpu().numpy()\n",
        "truth5 = truth5.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "ABeB-qWL6wIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(truth5, prediction5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRi2u07J7DdU",
        "outputId": "4ae5f218-e2e7-49f0-de70-4714c856f2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.21      0.20        29\n",
            "           1       0.14      0.19      0.16        16\n",
            "           2       0.38      0.26      0.31        38\n",
            "           3       0.14      0.18      0.15        17\n",
            "\n",
            "    accuracy                           0.22       100\n",
            "   macro avg       0.21      0.21      0.21       100\n",
            "weighted avg       0.25      0.22      0.23       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For binary tensor 6\n",
        "vgg_model.classifier[6].weight.data = nn.Parameter((binary_tensors[5]).float())"
      ],
      "metadata": {
        "id": "0-nSnv007Gad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img, label in dataloader:\n",
        "    output6=vgg_model(img)\n",
        "    truth6=label\n",
        "    break"
      ],
      "metadata": {
        "id": "eeKrNU6K7K6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction6 = torch.argmax(output6, dim = 1).detach().cpu().numpy()\n",
        "truth6 = truth6.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "ouoOWqne7NP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(truth6, prediction6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhX_yzSU7hQd",
        "outputId": "04cdfb03-82fc-420a-8481-667d7ca8ea52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.23      0.24        26\n",
            "           1       0.12      0.22      0.15         9\n",
            "           2       0.53      0.36      0.43        44\n",
            "           3       0.31      0.43      0.36        21\n",
            "\n",
            "    accuracy                           0.33       100\n",
            "   macro avg       0.30      0.31      0.30       100\n",
            "weighted avg       0.38      0.33      0.34       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Thus according to weighted avg, it comes maximum for binary tensor 4 and second maximum for 6. Thus we will take these and mutate them"
      ],
      "metadata": {
        "id": "sAE7mbbM7kUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define the two parent tensors\n",
        "\n",
        "\n",
        "# Define the mutation rate\n",
        "mutation_rate = 0.1\n",
        "\n",
        "# Create empty tensors to hold the offspring\n",
        "offspring1 = torch.empty_like(binary_tensors[3])\n",
        "offspring2 = torch.empty_like(binary_tensors[5])\n",
        "offspring3 = torch.empty_like(binary_tensors[3])\n",
        "offspring4 = torch.empty_like(binary_tensors[5])\n",
        "\n",
        "# Perform uniform mutation on the parents to create offspring\n",
        "for i in range(len(binary_tensors[3])):\n",
        "    if torch.rand(1) < mutation_rate:\n",
        "        # Perform mutation by randomly selecting a new value\n",
        "        offspring1[i] = torch.randint(0, 10, (1,))\n",
        "    else:\n",
        "        # Inherit from parent 1\n",
        "        offspring1[i] = binary_tensors[3][i]\n",
        "    \n",
        "    if torch.rand(1) < mutation_rate:\n",
        "        # Perform mutation by randomly selecting a new value\n",
        "        offspring2[i] = torch.randint(0, 10, (1,))\n",
        "    else:\n",
        "        # Inherit from parent 2\n",
        "        offspring2[i] = binary_tensors[5][i]\n",
        "    \n",
        "    if torch.rand(1) < mutation_rate:\n",
        "        # Perform mutation by randomly selecting a new value\n",
        "        offspring3[i] = torch.randint(0, 10, (1,))\n",
        "    else:\n",
        "        # Inherit from parent 1\n",
        "        offspring3[i] = binary_tensors[3][i]\n",
        "    \n",
        "    if torch.rand(1) < mutation_rate:\n",
        "        # Perform mutation by randomly selecting a new value\n",
        "        offspring4[i] = torch.randint(0, 10, (1,))\n",
        "    else:\n",
        "        # Inherit from parent 2\n",
        "        offspring4[i] = binary_tensors[5][i]\n",
        "\n",
        "# Print the offspring tensors\n",
        "print(\"Offspring 1:\", offspring1)\n",
        "print(\"Offspring 2:\", offspring2)\n",
        "print(\"Offspring 3:\", offspring3)\n",
        "print(\"Offspring 4:\", offspring4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP915oXh8DjN",
        "outputId": "9d48ea1b-f1da-4887-be98-bf8dbcd1973e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Offspring 1: tensor([[0, 0, 0,  ..., 1, 1, 0],\n",
            "        [1, 1, 1,  ..., 0, 1, 1],\n",
            "        [9, 9, 9,  ..., 9, 9, 9],\n",
            "        [0, 1, 0,  ..., 0, 0, 1]])\n",
            "Offspring 2: tensor([[1, 0, 0,  ..., 1, 0, 0],\n",
            "        [0, 1, 0,  ..., 0, 1, 0],\n",
            "        [1, 0, 1,  ..., 0, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 1, 0]])\n",
            "Offspring 3: tensor([[0, 0, 0,  ..., 1, 1, 0],\n",
            "        [1, 1, 1,  ..., 0, 1, 1],\n",
            "        [0, 1, 0,  ..., 1, 1, 1],\n",
            "        [0, 1, 0,  ..., 0, 0, 1]])\n",
            "Offspring 4: tensor([[1, 0, 0,  ..., 1, 0, 0],\n",
            "        [4, 4, 4,  ..., 4, 4, 4],\n",
            "        [1, 0, 1,  ..., 0, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 1, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define the two parent tensors\n",
        "\n",
        "# Define the mutation rate\n",
        "mutation_rate = 0.1\n",
        "\n",
        "# Create empty tensors to hold the offspring\n",
        "offspring1 = torch.empty_like(binary_tensors[3])\n",
        "offspring2 = torch.empty_like(binary_tensors[5])\n",
        "offspring3 = torch.empty_like(binary_tensors[3])\n",
        "offspring4 = torch.empty_like(binary_tensors[5])\n",
        "\n",
        "# Initialize the difference to a large number\n",
        "diff = float('inf')\n",
        "\n",
        "# Repeatedly mutate the offspring tensors until the difference between the parents and offspring is minimized\n",
        "while diff > 0:\n",
        "    # Perform uniform mutation on the parents to create offspring\n",
        "    for i in range(len(binary_tensors[3])):\n",
        "        if torch.rand(1) < mutation_rate:\n",
        "            # Perform mutation by randomly selecting a new value\n",
        "            offspring1[i] = torch.randint(0, 10, (1,))\n",
        "        else:\n",
        "            # Inherit from parent 1\n",
        "            offspring1[i] = binary_tensors[3][i]\n",
        "\n",
        "        if torch.rand(1) < mutation_rate:\n",
        "            # Perform mutation by randomly selecting a new value\n",
        "            offspring2[i] = torch.randint(0, 10, (1,))\n",
        "        else:\n",
        "            # Inherit from parent 2\n",
        "            offspring2[i] = binary_tensors[5][i]\n",
        "\n",
        "        if torch.rand(1) < mutation_rate:\n",
        "            # Perform mutation by randomly selecting a new value\n",
        "            offspring3[i] = torch.randint(0, 10, (1,))\n",
        "        else:\n",
        "            # Inherit from parent 1\n",
        "            offspring3[i] = binary_tensors[3][i]\n",
        "\n",
        "        if torch.rand(1) < mutation_rate:\n",
        "            # Perform mutation by randomly selecting a new value\n",
        "            offspring4[i] = torch.randint(0, 10, (1,))\n",
        "        else:\n",
        "            # Inherit from parent 2\n",
        "            offspring4[i] = binary_tensors[5][i]\n",
        "\n",
        "    # Calculate the difference between the parents and offspring tensors\n",
        "    diff = (binary_tensors[3] - offspring1).abs().sum() + \\\n",
        "           (binary_tensors[5]).abs().sum() + \\\n",
        "           (binary_tensors[3] - offspring3).abs().sum() + \\\n",
        "           (binary_tensors[5] - offspring4).abs().sum()\n",
        "\n",
        "    # Replace the parents with the offspring\n",
        "    binary_tensors[3] = offspring1\n",
        "    binary_tensors[5] = offspring2\n",
        "\n",
        "# Print the final parents and difference\n",
        "print(\"Final parent 1:\", binary_tensors[3])\n",
        "print(\"Final parent 2:\", binary_tensors[5])\n",
        "print(\"Final difference:\", diff)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCUcmU238jWy",
        "outputId": "1dc37fbe-cfd2-45f4-a8a4-3ae1c5afc794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final parent 1: tensor([[6, 6, 6,  ..., 6, 6, 6],\n",
            "        [9, 9, 9,  ..., 9, 9, 9],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [5, 5, 5,  ..., 5, 5, 5]])\n",
            "Final parent 2: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])\n",
            "Final difference: tensor(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Comparing performances of SGD, GD, Adam and Genetic Algorithm"
      ],
      "metadata": {
        "id": "mhuiJjeMWsU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets, models\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Set device to GPU if available, otherwise CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "inputs, labels = next(iter(dataloader))\n",
        "inputs = inputs.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "# Load pre-trained VGG16 model\n",
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "# Freeze all layers except the last fully connected layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.classifier[-1] = nn.Linear(in_features=4096, out_features=4)\n",
        "\n",
        "# Set loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Move model to device\n",
        "model = model.to(device)\n",
        "\n",
        "# Start training loop\n",
        "model.train()\n",
        "optimizer.zero_grad()\n",
        "outputs = model(inputs)\n",
        "loss = criterion(outputs, labels)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "# Calculate accuracy and print classification report\n",
        "preds = torch.max(outputs, 1)[1].cpu().numpy()\n",
        "targets = labels.cpu().numpy()\n",
        "print(classification_report(targets, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-uMIi4KRdd6",
        "outputId": "194ea7c4-4d13-4348-c90f-ba6bcbd88594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.11      0.16        27\n",
            "           1       0.09      0.60      0.16        10\n",
            "           2       0.64      0.20      0.31        45\n",
            "           3       0.10      0.06      0.07        18\n",
            "\n",
            "    accuracy                           0.19       100\n",
            "   macro avg       0.28      0.24      0.17       100\n",
            "weighted avg       0.39      0.19      0.21       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets, models\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Set device to GPU if available, otherwise CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "inputs, labels = next(iter(dataloader))\n",
        "inputs = inputs.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "# Load pre-trained VGG16 model\n",
        "model = models.vgg16(pretrained=True)\n",
        "dataloader_gd = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "# Freeze all layers except the last fully connected layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.classifier[-1] = nn.Linear(in_features=4096, out_features=4)\n",
        "\n",
        "# Set loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Move model to device\n",
        "model = model.to(device)\n",
        "\n",
        "# Start training loop\n",
        "model.train()\n",
        "optimizer.zero_grad()\n",
        "outputs = model(inputs)\n",
        "loss = criterion(outputs, labels)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "# Calculate accuracy and print classification report\n",
        "preds = torch.max(outputs, 1)[1].cpu().numpy()\n",
        "targets = labels.cpu().numpy()\n",
        "print(classification_report(targets, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK49JcuEetpS",
        "outputId": "d9295ac6-d592-457b-f22d-7c28d9a75267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.10      0.17        29\n",
            "           1       0.10      0.33      0.15        12\n",
            "           2       0.33      0.04      0.07        49\n",
            "           3       0.09      0.40      0.15        10\n",
            "\n",
            "    accuracy                           0.13       100\n",
            "   macro avg       0.24      0.22      0.13       100\n",
            "weighted avg       0.31      0.13      0.12       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets, models\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Set device to GPU if available, otherwise CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "inputs, labels = next(iter(dataloader))\n",
        "inputs = inputs.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "# Load pre-trained VGG16 model\n",
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "# Freeze all layers except the last fully connected layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.classifier[-1] = nn.Linear(in_features=4096, out_features=4)\n",
        "\n",
        "# Set loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Move model to device\n",
        "model = model.to(device)\n",
        "\n",
        "# Start training loop\n",
        "model.train()\n",
        "optimizer.zero_grad()\n",
        "outputs = model(inputs)\n",
        "loss = criterion(outputs, labels)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "# Calculate accuracy and print classification report\n",
        "preds = torch.max(outputs, 1)[1].cpu().numpy()\n",
        "targets = labels.cpu().numpy()\n",
        "print(classification_report(targets, preds))"
      ],
      "metadata": {
        "id": "VglsiFS-Wzan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(targets, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsbWihaeXxjy",
        "outputId": "f30f6fb6-0d8b-4c72-d78d-6bb042366093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.26      0.32        23\n",
            "           1       0.16      0.50      0.25        14\n",
            "           2       0.63      0.27      0.38        45\n",
            "           3       0.21      0.28      0.24        18\n",
            "\n",
            "    accuracy                           0.30       100\n",
            "   macro avg       0.36      0.33      0.30       100\n",
            "weighted avg       0.44      0.30      0.32       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Ko7FtPHeFAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#genetic\n",
        "vgg_model.classifier[6].weight.data = nn.Parameter((binary_tensors[3]).float())"
      ],
      "metadata": {
        "id": "gmmRKdC5YYvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img, label in dataloader:\n",
        "    output_ga=vgg_model(img)\n",
        "    truth_ga=label\n",
        "    break"
      ],
      "metadata": {
        "id": "-AGNoOuJZKl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_ga = torch.argmax(output_ga, dim = 1).detach().cpu().numpy()\n",
        "truth_ga = truth_ga.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "bwTJt28bZRRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(truth_ga, prediction_ga))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E_q2V8YZjOH",
        "outputId": "aeeaca25-ad70-436f-ae1c-ed01c3ff9d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        21\n",
            "           1       0.08      1.00      0.15         8\n",
            "           2       0.00      0.00      0.00        44\n",
            "           3       0.00      0.00      0.00        27\n",
            "\n",
            "    accuracy                           0.08       100\n",
            "   macro avg       0.02      0.25      0.04       100\n",
            "weighted avg       0.01      0.08      0.01       100\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0KzQx3Y1ZqZ1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}